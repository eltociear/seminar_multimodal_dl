<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>References | Multimodal Deep Learning</title>
  <meta name="description" content="In the last few years, there have been several breakthroughs in the methodologies used in Natural Language Processing (NLP) as well as Computer Vision (CV). Beyond these improvements on single-modality models, large-scale multi-modal approaches have become a very active area of research. In this seminar, we are planning to review these approaches and create a solid overview of the field, starting with the current state-of-the-art approaches in the two subfields of Deep Learning individually. We will further discuss modeling frameworks, where one modality is transformed into the other as well as models in which one modality is utilized to enhance representation learning for the other. Finally, we plan to also potentially cover other modalities as well as general-purpose multi-modal models, which are able to handle different tasks on different modalities within one unified architecture. Interesting applications/use cases could also be potential topics for a seminar paper." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="References | Multimodal Deep Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="In the last few years, there have been several breakthroughs in the methodologies used in Natural Language Processing (NLP) as well as Computer Vision (CV). Beyond these improvements on single-modality models, large-scale multi-modal approaches have become a very active area of research. In this seminar, we are planning to review these approaches and create a solid overview of the field, starting with the current state-of-the-art approaches in the two subfields of Deep Learning individually. We will further discuss modeling frameworks, where one modality is transformed into the other as well as models in which one modality is utilized to enhance representation learning for the other. Finally, we plan to also potentially cover other modalities as well as general-purpose multi-modal models, which are able to handle different tasks on different modalities within one unified architecture. Interesting applications/use cases could also be potential topics for a seminar paper." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="References | Multimodal Deep Learning" />
  
  <meta name="twitter:description" content="In the last few years, there have been several breakthroughs in the methodologies used in Natural Language Processing (NLP) as well as Computer Vision (CV). Beyond these improvements on single-modality models, large-scale multi-modal approaches have become a very active area of research. In this seminar, we are planning to review these approaches and create a solid overview of the field, starting with the current state-of-the-art approaches in the two subfields of Deep Learning individually. We will further discuss modeling frameworks, where one modality is transformed into the other as well as models in which one modality is utilized to enhance representation learning for the other. Finally, we plan to also potentially cover other modalities as well as general-purpose multi-modal models, which are able to handle different tasks on different modalities within one unified architecture. Interesting applications/use cases could also be potential topics for a seminar paper." />
  

<meta name="author" content="" />


<meta name="date" content="2022-05-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="acknowledgements.html"/>

<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block/empty-anchor.js"></script>
<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Multimodal Deep Learning></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a><ul>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html#technical-setup"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#intro-about-the-seminar-topic"><i class="fa fa-check"></i><b>1.1</b> Intro About the Seminar Topic</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#outline-of-the-booklet"><i class="fa fa-check"></i><b>1.2</b> Outline of the Booklet</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-1.html"><a href="chapter-1.html"><i class="fa fa-check"></i><b>2</b> Chapter 1</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter-1.html"><a href="chapter-1.html#lorem-ipsum"><i class="fa fa-check"></i><b>2.1</b> Lorem Ipsum</a></li>
<li class="chapter" data-level="2.2" data-path="chapter-1.html"><a href="chapter-1.html#using-figures"><i class="fa fa-check"></i><b>2.2</b> Using Figures</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-1.html"><a href="chapter-1.html#using-tex"><i class="fa fa-check"></i><b>2.3</b> Using Tex</a></li>
<li class="chapter" data-level="2.4" data-path="chapter-1.html"><a href="chapter-1.html#using-stored-results"><i class="fa fa-check"></i><b>2.4</b> Using Stored Results</a></li>
<li class="chapter" data-level="2.5" data-path="chapter-1.html"><a href="chapter-1.html#title"><i class="fa fa-check"></i><b>2.5</b> title</a></li>
<li class="chapter" data-level="2.6" data-path="chapter-1.html"><a href="chapter-1.html#title-1"><i class="fa fa-check"></i><b>2.6</b> title</a></li>
<li class="chapter" data-level="2.7" data-path="chapter-1.html"><a href="chapter-1.html#title-2"><i class="fa fa-check"></i><b>2.7</b> title</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-1-1.html"><a href="chapter-1-1.html"><i class="fa fa-check"></i><b>3</b> Chapter 1</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter-1-1.html"><a href="chapter-1-1.html#lorem-ipsum-1"><i class="fa fa-check"></i><b>3.1</b> Lorem Ipsum</a></li>
<li class="chapter" data-level="3.2" data-path="chapter-1-1.html"><a href="chapter-1-1.html#using-figures-1"><i class="fa fa-check"></i><b>3.2</b> Using Figures</a></li>
<li class="chapter" data-level="3.3" data-path="chapter-1-1.html"><a href="chapter-1-1.html#using-tex-1"><i class="fa fa-check"></i><b>3.3</b> Using Tex</a></li>
<li class="chapter" data-level="3.4" data-path="chapter-1-1.html"><a href="chapter-1-1.html#using-stored-results-1"><i class="fa fa-check"></i><b>3.4</b> Using Stored Results</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="title-3.html"><a href="title-3.html"><i class="fa fa-check"></i><b>4</b> title</a></li>
<li class="chapter" data-level="5" data-path="title-4.html"><a href="title-4.html"><i class="fa fa-check"></i><b>5</b> title</a></li>
<li class="chapter" data-level="6" data-path="title-5.html"><a href="title-5.html"><i class="fa fa-check"></i><b>6</b> title</a></li>
<li class="chapter" data-level="7" data-path="title-6.html"><a href="title-6.html"><i class="fa fa-check"></i><b>7</b> title</a></li>
<li class="chapter" data-level="8" data-path="title-7.html"><a href="title-7.html"><i class="fa fa-check"></i><b>8</b> title</a></li>
<li class="chapter" data-level="9" data-path="title-8.html"><a href="title-8.html"><i class="fa fa-check"></i><b>9</b> title</a></li>
<li class="chapter" data-level="10" data-path="chapter-2-multimodal-architectures.html"><a href="chapter-2-multimodal-architectures.html"><i class="fa fa-check"></i><b>10</b> Chapter 2 Multimodal architectures</a><ul>
<li class="chapter" data-level="10.1" data-path="chapter-2-multimodal-architectures.html"><a href="chapter-2-multimodal-architectures.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="title-9.html"><a href="title-9.html"><i class="fa fa-check"></i><b>11</b> title</a></li>
<li class="chapter" data-level="12" data-path="title-10.html"><a href="title-10.html"><i class="fa fa-check"></i><b>12</b> title</a></li>
<li class="chapter" data-level="13" data-path="title-11.html"><a href="title-11.html"><i class="fa fa-check"></i><b>13</b> title</a></li>
<li class="chapter" data-level="14" data-path="title-12.html"><a href="title-12.html"><i class="fa fa-check"></i><b>14</b> title</a></li>
<li class="chapter" data-level="15" data-path="title-13.html"><a href="title-13.html"><i class="fa fa-check"></i><b>15</b> title</a></li>
<li class="chapter" data-level="16" data-path="epilogue.html"><a href="epilogue.html"><i class="fa fa-check"></i><b>16</b> Epilogue</a><ul>
<li class="chapter" data-level="16.1" data-path="epilogue.html"><a href="epilogue.html#test"><i class="fa fa-check"></i><b>16.1</b> test</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>17</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multimodal Deep Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered hasAnchor">
<h1>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h1>

<div id="refs" class="references">
<div>
<p>Baevski, Alexei, Wei-Ning Hsu, Qiantong Xu, Arun Babu, Jiatao Gu, and Michael Auli. 2022. “Data2vec: A General Framework for Self-Supervised Learning in Speech, Vision and Language.” <em>arXiv Preprint arXiv:2202.03555</em>.</p>
</div>
<div>
<p>Bordes, Patrick, Eloi Zablocki, Laure Soulier, Benjamin Piwowarski, and Patrick Gallinari. 2020. “Incorporating Visual Semantics into Sentence Representations Within a Grounded Space.” <em>arXiv Preprint arXiv:2002.02734</em>.</p>
</div>
<div>
<p>Brown, Tom, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” <em>Advances in Neural Information Processing Systems</em> 33: 1877–1901.</p>
</div>
<div>
<p>Cornia, Marcella, Matteo Stefanini, Lorenzo Baraldi, and Rita Cucchiara. 2020. “Meshed-Memory Transformer for Image Captioning.” In <em>Proceedings of the Ieee/Cvf Conference on Computer Vision and Pattern Recognition</em>.</p>
</div>
<div>
<p>Harnad, Stevan. 1990. “The Symbol Grounding Problem.” <em>Physica D: Nonlinear Phenomena</em> 42 (1-3): 335–46.</p>
</div>
<div>
<p>Lin, Tsung-Yi, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C. Lawrence Zitnick. 2014. “Microsoft Coco: Common Objects in Context.” In <em>Computer Vision – Eccv 2014</em>, edited by David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars, 740–55. Cham: Springer International Publishing.</p>
</div>
<div>
<p>Nichol, Alex, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. 2021. “GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models.” <em>CoRR</em> abs/2112.10741. <a href="https://arxiv.org/abs/2112.10741">https://arxiv.org/abs/2112.10741</a>.</p>
</div>
<div>
<p>Radford, Alec, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, et al. 2021. “Learning Transferable Visual Models from Natural Language Supervision.” In <em>International Conference on Machine Learning</em>, 8748–63. PMLR.</p>
</div>
<div>
<p>Ramesh, Aditya, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. 2021. “Zero-Shot Text-to-Image Generation.” In <em>Proceedings of the 38th International Conference on Machine Learning</em>, edited by Marina Meila and Tong Zhang, 139:8821–31. Proceedings of Machine Learning Research. PMLR. <a href="https://proceedings.mlr.press/v139/ramesh21a.html">https://proceedings.mlr.press/v139/ramesh21a.html</a>.</p>
</div>
<div>
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.</p>
</div>
<div>
<p>Silberer, Carina, and Mirella Lapata. 2012. “Grounded Models of Semantic Representation.” In <em>Tsujii J, Henderson J, Paşca M, Editors. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning; 2012 Jul 12–14; Jeju Island, Korea. Stroudsburg: ACL; 2012. P. 1423-33.</em> ACL (Association for Computational Linguistics).</p>
</div>
<div>
<p>Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” <em>Advances in Neural Information Processing Systems</em> 30.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="acknowledgements.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
