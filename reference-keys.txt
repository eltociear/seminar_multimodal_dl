fig:onehot
fig:embedPilehvarP11
fig:embedVectors
fig:embedTransl
fig:embedArch
fig:arch1Encdec
fig:encdecArchCho
fig:encdecArch2
fig:attentionExStanford
fig:attentionfocus
fig:tfrnnlimstanford
fig:tfrnnlim2stanford
fig:tfselfa
fig:tfhashtable
fig:tfsdpa
fig:tfmha
fig:tfarch
fig:tfpretrain
fig:tfpretrain2
fig:t5
fig:gpt3scaling
fig:ctattentionheads
fig:gpt3fewshotlearning
eq:ch01-02-01
fig:ch01-figure01
eq:ch01-02-02
fig:ch01-figure02
fig:ch01-figure03
eq:01-02-06
fig:ch01-figure04
fig:ch01-figure05
fig:ch01-figure06
fig:ch01-figure7
fig:f02-00-01
fig:imagetype
fig:cocoannotation
fig:cococomparison
fig:m2arc1
fig:m2arc2
eq:binom
fig:compare1
fig:compare2
fig:example2
fig:hamsterdragon
fig:fiddistortions
fig:precisionandrecall
fig:vanillagan
fig:vanillagansamples
fig:gancls
fig:ganclsembeddings
fig:interpolatingbirds
fig:ganclszeroshot
fig:ganclsmscoco
fig:stackgan
fig:attngan
fig:vae
fig:vqvae
fig:dallephotorealism
fig:dalleexamples
fig:glidefid
fig:gliderealism
fig:glideresults
fig:glidefails
fig:uncliptable
fig:unclipimages
fig:cube
fig:sign
fig:timessquare
fig:partiresults
fig:partiimages
fig:bias
fig:img-hist
fig:img-kiela2014-01
fig:img-lazaridou2015-01
fig:img-tan2020-04
fig:img-tan2020-01
fig:img-tan2020-05
fig:img-lu2022-01
fig:img-eval01
fig:img-2014hill-01
fig:img-tan2020-02
fig:img-tan2020-03
fig:img-pezzele2021-01
fig:img-pezzele2021-02
fig:img-lu2022-02
eq:contrLoss
fig:contr-viz
fig:contr-vs-pred-learn
fig:data-efficiency
fig:zero-shooting
eq:contrLossCLIP
fig:performance-clip
fig:attention-ViT
fig:img-txt-addition
fig:florence-dimensions
fig:florence-architecture
fig:table1
fig:table2
fig:table3
fig:vltasks
fig:data2vecoverview
fig:visiontransformer
fig:data2vecresults1
fig:data2vecresults2
fig:vilbertarc
fig:vilbertattention
fig:vilbertmaps
fig:vilbertresults
fig:flamingoexamples
fig:flamingoarc
fig:perceiver
fig:flamingoattention
fig:flamingodatasets
fig:flamingoresult
fig:flamingfinetune
fig:struc-vs-unstrc
fig:fusion-strategies
fig:cheerla-model
fig:wide-deep-nn
fig:SSDDR
fig:model-heads
fig:multimodel
fig:unit
fig:ofa
fig:pathways
fig:pathnet
fig:LIMoE
fig:Logo
fig:DeepDream
fig:StyleTransfer2
fig:GAN
fig:comparison1
fig:comparison2
fig:inpainting
fig:sketch
introduction
introduction-to-multimodal-deep-learning
outline-of-the-booklet
c01-00-intro-modalities
c01-01-sota-nlp
introduction-1
word-embeddings
encoder-decoder
attention
transformer
transformer-architectures-bert-t5-gpt-3
bert
t5
gpt-3
current-topics
sec:concerns-lm
improving-understanding-of-transformer-based-models
few-shot-learning
summary
c01-02-sota-cv
history
supervised-and-unsupervised-learning
scaling-networks
deep-residual-networks
deep-residual-learning
residual-learning
identity-mapping-by-shortcuts
network-architectures
efficientnet
compound-model-scaling
problem-formulation
scaling-dimensions
compound-scaling
efficientnet-architecture
results-and-comparison-of-the-networks
contrastive-learning
a-simple-framework-for-contrastive-learning-of-visual-representations
the-contrastive-learning-framework
stochastic-data-augmentation-module
neural-network-base-encoder
small-neural-network-projection-head
contrastive-loss-function
bootstrap-your-own-latent
description-of-the-method
comparison-of-contrastive-learning-frameworks
transformers-in-computer-vision
vision-transformers
method
experiments
conclusion
c01-03-benchmarks
datasets
natural-language-processing-datasets
common-crawl
the-pile
multilingual-datasets
bookscorpus
computer-vision-dataset
imagenet
joint-foto-tree-jft-entity-foto-tree-eft
objects365
microsoft-common-objects-in-context-coco
multi-modal-datasets
laion-400m-5b
localized-narratives
wudaomm
wikipedia-image-text-wit
bias-in-datasets
pre-training-tasks
benchmarks
natural-language-processing-benchmarks
superglue
stanford-question-answering-dataset-squad-1.0-2.0
beyond-the-imitation-game-benchmark-big-bench
wmt
checklist
computer-vision-benchmarks
imagenet-versions
ms-coco-object365
ade20k
multi-modal-benchmarks
visual-commonsense-reasoning-vcr
visual-question-answering-1.0-2.0-vqa
gqa
generative-benchmarks
partiprompts-drawbench-localized-narratives
foil-it
valse
other-benchmarks
c02-00-multimodal
c02-01-img2text
microsoft-coco-common-objects-in-context
image-collection-and-annotation-for-ms-coco
comparison-with-other-datasets
discussion
models-for-image-captioning
meshed-memory-transformer-for-image-captioning-m2
m2-transformer-architecture
memory-augmented-encoder
meshed-decoder
comparison-with-other-models-on-coco-datasets
c02-02-text2img
seeking-objectivity
generative-adversarial-networks
vanilla-gan-for-image-generation
conditioning-on-text
further-gan-like-development
dall-e-1
glide
dall-e-2-unclip
imagen-parti
discussion-1
c02-03-img-support-text
words-in-non-symbolic-contexts
word-embeddings-survival-kit
the-beginning-sequential-multimodal-embeddings
the-grounded-space
the-transformers-era
vokenization
the-relevance-score-function-model-training-inference
one-step-further-the-power-of-imagination
was-it-worth
evaluation-in-the-pre-transformers-era
evaluation-in-the-post-transformers-era
the-end-of-this-story
appendix-selected-models---summary
c02-04-text-support-img
introduction-2
concepts
webScaleData
contrObj
foundMod
architectures
clip
align
florence
performanceComp
resources
c02-05-text-plus-img
data2vec
vision-and-language-bert-vilbert
flamingo
discussion-2
c03-00-further
c03-01-further-modalities
taxonomy-of-multimodal-challenges
multimodal-representation-learning
joint-representations
coordinated-representation
multimodal-alignment
multimodal-fusion
multimodal-translation
retrieval
generation
current-research-trends-generalized-self-supervised-multimodal-perception
general-multimodal-architectures
n√ºwa
perceiver-io
hierarchical-perceiver
multimodal-training-paradigms
uni-modal-modality-agnostic-self-supervised-learning
multimodal-self-supervised-learning
personal-research-general-non-contrastive-multimodal-representation-learning
looking-forward
c03-02-structured-unstructured
intro
taxonomy-structured-vs.-unstructured-data
fusion-strategies
applications
multimodal-dl-in-survival
traditional-survival-analysis-cph-model
multimodal-dl-survival-analysis
multimodal-dl-in-other-scientific-fields
conclusion-and-outlook
c03-03-multi-purpose
intro-1
multi-purpose-models
previous-work
multimodel
unified-transformer-unit
ofa---once-for-all
gato---a-generalist-agent
comparison
pathway-proposal
idea
related-work-to-pathways
pathnet
limoe
munet-multitask-network
conclusion-pathways
discussion-3
c03-04-usecase
historical-overview
how-to-use-models
different-tasks-and-modalities
discussion-and-prospects
conclusion-1
epilogue
new-influential-architectures
acknowledgements
