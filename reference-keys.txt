fig:ch01-figure01
fig:ch01-figure02
fig:ch01-figure03
fig:ch01-figure04
fig:ch01-figure05
fig:ch01-figure06
fig:ch01-figure7
fig:unnamed-chunk-1
fig:imagetype
fig:cocoannotation
fig:cococomparison
fig:m2arc1
fig:m2arc2
eq:binom
fig:compare1
fig:compare2
fig:example2
fig:img-hist
fig:img-kiela2014-01
fig:img-lazaridou2015-01
fig:img-tan2020-04
fig:img-tan2020-01
fig:img-tan2020-05
fig:img-lu2022-01
fig:img-eval01
fig:img-2014hill-01
fig:img-tan2020-02
fig:img-tan2020-03
fig:img-pezzele2021-01
fig:img-pezzele2021-02
fig:img-lu2022-02
eq:contrLoss
fig:contr-viz
fig:contr-vs-pred-learn
fig:data-efficiency
fig:zero-shooting
eq:contrLossCLIP
fig:performance-clip
fig:attention-ViT
fig:img-txt-addition
fig:florence-dimensions
fig:florence-architecture
fig:table1
fig:table2
fig:table3
fig:vltasks
fig:data2vecoverview
fig:visiontransformer
fig:data2vecresults1
fig:data2vecresults2
fig:vilbertarc
fig:vilbertattention
fig:vilbertmaps
fig:vilbertresults
fig:flamingoexamples
fig:flamingoarc
fig:perceiver
fig:flamingoattention
fig:flamingodatasets
fig:flamingoresult
fig:flamingfinetune
fig:struc-vs-unstrc
fig:fusion-strategies
fig:cheerla-model
fig:wide-deep-nn
fig:SSDDR
fig:model-heads
fig:multimodel
fig:unit
fig:ofa
fig:pathways
fig:pathnet
fig:LIMoE
fig:Logo
fig:DeepDream
fig:StyleTransfer2
fig:GAN
fig:comparison1
fig:comparison2
fig:inpainting
fig:sketch
introduction
introduction-to-multimodal-deep-learning
outline-of-the-booklet
c01-00-intro-modalities
c01-01-sota-nlp
c01-02-sota-cv
history
supervised-and-unsupervised-learning
scaling-networks
deep-residual-networks
deep-residual-learning
residual-learning
identity-mapping-by-shortcuts
network-architectures
efficientnet
compound-model-scaling
problem-formulation
scaling-dimensions
compound-scaling
efficientnet-architecture
results-and-comparison-of-the-networks
contrastive-learning
a-simple-framework-for-contrastive-learning-of-visual-representations
the-contrastive-learning-framework
stochastic-data-augmentation-module
neural-network-base-encoder
small-neural-network-projection-head
contrastive-loss-function
bootstrap-your-own-latent
description-of-method
comparison-of-contrastive-learning-frameworks
transformers-in-computer-vision
vision-transformers
method
experiments
conclusion
c01-03-benchmarks
datasets
natural-language-processing-datasets
common-crawl
the-pile
multilingual-datasets
bookscorpus
computer-vision-dataset
imagenet
joint-foto-tree-jft-entity-foto-tree-eft
objects365
microsoft-common-objects-in-context-coco
multi-modal-datasets
laion-400m-5b
localized-narratives
wudaomm
wikipedia-image-text-wit
bias-in-datasets
pre-training-tasks
benchmarks
natural-language-processing-benchmarks
superglue
stanford-question-answering-dataset-squad-1.0-2.0
beyond-the-imitation-game-benchmark-big-bench
wmt
checklist
computer-vision-benchmarks
imagenet-versions
ms-coco-object365
ade20k
multi-modal-benchmarks
visual-commonsense-reasoning-vcr
visual-question-answering-1.0-2.0-vqa
gqa
generative-benchmarks
partiprompts-drawbench-localized-narratives
foil-it
valse
other-benchmarks
c02-00-multimodal
c02-01-img2text
microsoft-coco-common-objects-in-context
image-collection-and-annotation-for-ms-coco
comparison-with-other-datasets
discussion
models-for-image-captioning
meshed-memory-transformer-for-image-captioning-m2
m2-transformer-architecture
memory-augmented-encoder
meshed-decoder
comparison-with-other-models-on-coco-datasets
c02-02-text2img
seeking-objectivity
datasets-1
measures
generative-adversarial-networks
vanilla-gan-for-image-generation
conditioning-on-text
stacking-generators
is-attention-all-you-need
variational-autoencoder
dall-e-starting-post-gan-era
glide
dall-e-2
imagen
parti
open-source-community
discussion-1
c02-03-img-support-text
words-in-non-symbolic-contexts
word-embeddings-survival-kit
the-beginning-sequential-multimodal-embeddings
the-grounded-space
the-transformers-era
vokenization
the-relevance-score-function-model-training-inference
one-step-further-the-power-of-imagination
was-it-worth
evaluation-in-the-pre-transformers-era
evaluation-in-the-post-transformers-era
the-end-of-this-story
appendix-selected-models---summary
c02-04-text-support-img
introduction-1
concepts
webScaleData
contrObj
foundMod
architectures
clip
align
florence
performanceComp
resources
c02-05-text-plus-img
data2vec
vision-and-language-bert-vilbert
flamingo
discussion-2
c03-00-further
c03-01-further-modalities
intro
motivation
taxonomy-of-multimodal-challenges
multimodal-representation-learning
joint-representations
coordinated-representation
multimodal-translation
multimodal-alignment
multimodal-fusion
general-multimodal-architectures
multimodal-training-paradigms
modality-agnostic-uni-modal-ssl
generalized-cross-modal-ssl
contrastive-methods
non-contrastive-methods
combining-general-architectures-and-training-paradigms
c03-02-structured-unstructured
intro-1
taxonomy-structured-vs.-unstructured-data
fusion-strategies
applications
multimodal-dl-in-survival
traditional-survival-analysis-cph-model
multimodal-dl-survival-analysis
multimodal-dl-in-other-scientific-fields
conclusion-and-outlook
c03-03-multi-purpose
intro-2
multi-purpose-models
previous-work
multimodel
unified-transformer-unit
ofa---once-for-all
gato---a-generalist-agent
comparison
pathway-proposal
idea
related-work-to-pathways
pathnet
limoe
munet-multitask-network
conclusion-pathways
discussion-3
c03-04-usecase
historical-overview
how-to-use-models
different-tasks-and-modalities
discussion-and-prospects
conclusion-1
epilogue
new-influential-architectures
acknowledgements
