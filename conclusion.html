<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Conclusion | Multimodal Deep Learning</title>
  <meta name="description" content="." />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Conclusion | Multimodal Deep Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Conclusion | Multimodal Deep Learning" />
  
  <meta name="twitter:description" content="." />
  

<meta name="author" content="" />


<meta name="date" content="2022-09-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="title.html"/>
<link rel="next" href="epilogue.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block/empty-anchor.js"></script>
<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Multimodal Deep Learning></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a><ul>
<li class="chapter" data-level="0.1" data-path="foreword.html"><a href="foreword.html#citation"><i class="fa fa-check"></i><b>0.1</b> Citation</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html#technical-setup"><i class="fa fa-check"></i>Technical Setup</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-to-multimodal-deep-learning"><i class="fa fa-check"></i><b>1.1</b> Introduction to Multimodal Deep Learning</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#outline-of-the-booklet"><i class="fa fa-check"></i><b>1.2</b> Outline of the Booklet</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#header1-01-00-intro-modalities"><i class="fa fa-check"></i><b>1.2.1</b> Header1 {#01-00-intro-modalities}</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction.html"><a href="introduction.html#header2-01-01-sota-nlp"><i class="fa fa-check"></i><b>1.2.2</b> Header2 {#01-01-sota-nlp}</a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction.html"><a href="introduction.html#header3-01-02-sota-cv"><i class="fa fa-check"></i><b>1.2.3</b> Header3 {#01-02-sota-cv}</a></li>
<li class="chapter" data-level="1.2.4" data-path="introduction.html"><a href="introduction.html#header4-01-03-benchmarks"><i class="fa fa-check"></i><b>1.2.4</b> Header4 {#01-03-benchmarks}</a></li>
<li class="chapter" data-level="1.2.5" data-path="introduction.html"><a href="introduction.html#header5-02-00-multimodal"><i class="fa fa-check"></i><b>1.2.5</b> Header5 {#02-00-multimodal}</a></li>
<li class="chapter" data-level="1.2.6" data-path="introduction.html"><a href="introduction.html#header6-02-01-img2text"><i class="fa fa-check"></i><b>1.2.6</b> Header6 {#02-01-img2text}</a></li>
<li class="chapter" data-level="1.2.7" data-path="introduction.html"><a href="introduction.html#header7-02-02-text2img"><i class="fa fa-check"></i><b>1.2.7</b> Header7 {#02-02-text2img}</a></li>
<li class="chapter" data-level="1.2.8" data-path="introduction.html"><a href="introduction.html#header8-02-03-img-support-text"><i class="fa fa-check"></i><b>1.2.8</b> Header8 {#02-03-img-support-text}</a></li>
<li class="chapter" data-level="1.2.9" data-path="introduction.html"><a href="introduction.html#header9-02-04-text-support-img"><i class="fa fa-check"></i><b>1.2.9</b> Header9 {#02-04-text-support-img}</a></li>
<li class="chapter" data-level="1.2.10" data-path="introduction.html"><a href="introduction.html#header10-02-05-text-plus-img"><i class="fa fa-check"></i><b>1.2.10</b> Header10 {#02-05-text-plus-img}</a></li>
<li class="chapter" data-level="1.2.11" data-path="introduction.html"><a href="introduction.html#header11-03-00-further"><i class="fa fa-check"></i><b>1.2.11</b> Header11 {#03-00-further}</a></li>
<li class="chapter" data-level="1.2.12" data-path="introduction.html"><a href="introduction.html#header12-03-01-further-modalities"><i class="fa fa-check"></i><b>1.2.12</b> Header12 {#03-01-further-modalities}</a></li>
<li class="chapter" data-level="1.2.13" data-path="introduction.html"><a href="introduction.html#header13-03-02-structured-unstructured"><i class="fa fa-check"></i><b>1.2.13</b> Header13 {#03-02-structured-unstructured}</a></li>
<li class="chapter" data-level="1.2.14" data-path="introduction.html"><a href="introduction.html#header14-03-03-multi-purpose"><i class="fa fa-check"></i><b>1.2.14</b> Header14 {#03-03-multi-purpose}</a></li>
<li class="chapter" data-level="1.2.15" data-path="introduction.html"><a href="introduction.html#header15-03-04-usecase"><i class="fa fa-check"></i><b>1.2.15</b> Header15 {#03-04-usecase}</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html"><i class="fa fa-check"></i><b>2</b> Introducing the modalities</a><ul>
<li class="chapter" data-level="2.1" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#state-of-the-art-in-computer-vision"><i class="fa fa-check"></i><b>2.1</b> State-of-the-art in computer vision</a><ul>
<li class="chapter" data-level="2.1.1" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#history"><i class="fa fa-check"></i><b>2.1.1</b> History</a></li>
<li class="chapter" data-level="2.1.2" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#supervised-and-unsupervised-learning"><i class="fa fa-check"></i><b>2.1.2</b> Supervised and unsupervised learning</a></li>
<li class="chapter" data-level="2.1.3" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#resnet"><i class="fa fa-check"></i><b>2.1.3</b> ResNet</a></li>
<li class="chapter" data-level="2.1.4" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#efficientnet"><i class="fa fa-check"></i><b>2.1.4</b> EfficientNet</a></li>
<li class="chapter" data-level="2.1.5" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#simclr"><i class="fa fa-check"></i><b>2.1.5</b> SimCLR</a></li>
<li class="chapter" data-level="2.1.6" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#bootstrap-your-own-latent-byol"><i class="fa fa-check"></i><b>2.1.6</b> Bootstrap Your Own Latent (BYOL)</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#resources-and-benchmarks-for-nlp-cv-and-multimodal-tasks"><i class="fa fa-check"></i><b>2.2</b> Resources and Benchmarks for NLP, CV and multimodal tasks</a><ul>
<li class="chapter" data-level="2.2.1" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#datasets"><i class="fa fa-check"></i><b>2.2.1</b> Datasets</a></li>
<li class="chapter" data-level="2.2.2" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#pre-training-tasks"><i class="fa fa-check"></i><b>2.2.2</b> Pre-Training Tasks</a></li>
<li class="chapter" data-level="2.2.3" data-path="introducing-the-modalities.html"><a href="introducing-the-modalities.html#benchmarks"><i class="fa fa-check"></i><b>2.2.3</b> Benchmarks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html"><i class="fa fa-check"></i><b>3</b> Multimodal architectures</a><ul>
<li class="chapter" data-level="3.1" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#img2text"><i class="fa fa-check"></i><b>3.1</b> img2text</a><ul>
<li class="chapter" data-level="3.1.1" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#microsoft-coco-common-objects-in-context"><i class="fa fa-check"></i><b>3.1.1</b> 2.1.1 Microsoft COCO: Common Objects in Context</a></li>
<li class="chapter" data-level="3.1.2" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#meshed-memory-transformer-for-image-captioning-m2"><i class="fa fa-check"></i><b>3.1.2</b> 2.1.2 Meshed-Memory Transformer for Image Captioning (<span class="math inline">\(M^2\)</span>)</a></li>
<li class="chapter" data-level="3.1.3" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#seeking-objectivity"><i class="fa fa-check"></i><b>3.1.3</b> Seeking objectivity</a></li>
<li class="chapter" data-level="3.1.4" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#generative-adversarial-networks"><i class="fa fa-check"></i><b>3.1.4</b> Generative Adversarial Networks</a></li>
<li class="chapter" data-level="3.1.5" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#dall-e-starting-post-gan-era"><i class="fa fa-check"></i><b>3.1.5</b> Dall-E starting post-GAN era</a></li>
<li class="chapter" data-level="3.1.6" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#glide"><i class="fa fa-check"></i><b>3.1.6</b> GLIDE</a></li>
<li class="chapter" data-level="3.1.7" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#dall-e-2"><i class="fa fa-check"></i><b>3.1.7</b> Dall-E 2</a></li>
<li class="chapter" data-level="3.1.8" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#imagen"><i class="fa fa-check"></i><b>3.1.8</b> Imagen</a></li>
<li class="chapter" data-level="3.1.9" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#parti"><i class="fa fa-check"></i><b>3.1.9</b> Parti</a></li>
<li class="chapter" data-level="3.1.10" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#open-source-community"><i class="fa fa-check"></i><b>3.1.10</b> Open-Source Community</a></li>
<li class="chapter" data-level="3.1.11" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#discussion"><i class="fa fa-check"></i><b>3.1.11</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#images-supporting-language-models"><i class="fa fa-check"></i><b>3.2</b> Images supporting language models</a><ul>
<li class="chapter" data-level="3.2.1" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#words-in-non-symbolic-contexts"><i class="fa fa-check"></i><b>3.2.1</b> Words In (Non-Symbolic) Contexts</a></li>
<li class="chapter" data-level="3.2.2" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#word-embeddings-survival-kit"><i class="fa fa-check"></i><b>3.2.2</b> Word-Embeddings: Survival-Kit</a></li>
<li class="chapter" data-level="3.2.3" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#the-beginning-sequential-multimodal-embeddings"><i class="fa fa-check"></i><b>3.2.3</b> The Beginning: Sequential Multimodal Embeddings</a></li>
<li class="chapter" data-level="3.2.4" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#the-grounded-space"><i class="fa fa-check"></i><b>3.2.4</b> The Grounded Space</a></li>
<li class="chapter" data-level="3.2.5" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#the-transformers-era"><i class="fa fa-check"></i><b>3.2.5</b> The Transformers Era</a></li>
<li class="chapter" data-level="3.2.6" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#was-it-worth"><i class="fa fa-check"></i><b>3.2.6</b> Was It Worth?</a></li>
<li class="chapter" data-level="3.2.7" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#the-end-of-this-story"><i class="fa fa-check"></i><b>3.2.7</b> The End Of This Story</a></li>
<li class="chapter" data-level="3.2.8" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#appendix-selected-models---summary"><i class="fa fa-check"></i><b>3.2.8</b> Appendix: Selected Models - Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#text-supporting-computer-vision-models"><i class="fa fa-check"></i><b>3.3</b> Text supporting computer vision models</a><ul>
<li class="chapter" data-level="3.3.1" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#intro"><i class="fa fa-check"></i><b>3.3.1</b> Intro</a></li>
<li class="chapter" data-level="3.3.2" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#concepts"><i class="fa fa-check"></i><b>3.3.2</b> Concepts</a></li>
<li class="chapter" data-level="3.3.3" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#contrastive-loss"><i class="fa fa-check"></i><b>3.3.3</b> Contrastive loss</a></li>
<li class="chapter" data-level="3.3.4" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#clip"><i class="fa fa-check"></i><b>3.3.4</b> CLIP</a></li>
<li class="chapter" data-level="3.3.5" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#align"><i class="fa fa-check"></i><b>3.3.5</b> ALIGN</a></li>
<li class="chapter" data-level="3.3.6" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#florence"><i class="fa fa-check"></i><b>3.3.6</b> Florence</a></li>
<li class="chapter" data-level="3.3.7" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#performance-comparison"><i class="fa fa-check"></i><b>3.3.7</b> Performance comparison</a></li>
<li class="chapter" data-level="3.3.8" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#resources"><i class="fa fa-check"></i><b>3.3.8</b> Resources</a></li>
<li class="chapter" data-level="3.3.9" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#outlook"><i class="fa fa-check"></i><b>3.3.9</b> Outlook</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#text-image"><i class="fa fa-check"></i><b>3.4</b> Text + Image</a><ul>
<li class="chapter" data-level="3.4.1" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#todo"><i class="fa fa-check"></i><b>3.4.1</b> Todo</a></li>
<li class="chapter" data-level="3.4.2" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#challenges-in-ai"><i class="fa fa-check"></i><b>3.4.2</b> challenges in AI</a></li>
<li class="chapter" data-level="3.4.3" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#vilbert"><i class="fa fa-check"></i><b>3.4.3</b> vilbert</a></li>
<li class="chapter" data-level="3.4.4" data-path="multimodal-architectures.html"><a href="multimodal-architectures.html#flamingo-alayrac2022flamingo"><i class="fa fa-check"></i><b>3.4.4</b> flamingo <span class="citation">(<span class="citeproc-not-found" data-reference-id="alayrac2022flamingo"><strong>???</strong></span>)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="further-topics.html"><a href="further-topics.html"><i class="fa fa-check"></i><b>4</b> Further Topics</a><ul>
<li class="chapter" data-level="4.1" data-path="further-topics.html"><a href="further-topics.html#including-further-modalities"><i class="fa fa-check"></i><b>4.1</b> Including Further Modalities</a><ul>
<li class="chapter" data-level="4.1.1" data-path="further-topics.html"><a href="further-topics.html#intro-1"><i class="fa fa-check"></i><b>4.1.1</b> Intro</a></li>
<li class="chapter" data-level="4.1.2" data-path="further-topics.html"><a href="further-topics.html#motivation"><i class="fa fa-check"></i><b>4.1.2</b> Motivation</a></li>
<li class="chapter" data-level="4.1.3" data-path="further-topics.html"><a href="further-topics.html#taxonomy-of-multimodal-challenges"><i class="fa fa-check"></i><b>4.1.3</b> Taxonomy of Multimodal Challenges</a></li>
<li class="chapter" data-level="4.1.4" data-path="further-topics.html"><a href="further-topics.html#general-multimodal-architectures"><i class="fa fa-check"></i><b>4.1.4</b> General Multimodal Architectures</a></li>
<li class="chapter" data-level="4.1.5" data-path="further-topics.html"><a href="further-topics.html#multimodal-training-paradigms"><i class="fa fa-check"></i><b>4.1.5</b> Multimodal Training Paradigms</a></li>
<li class="chapter" data-level="4.1.6" data-path="further-topics.html"><a href="further-topics.html#combining-general-architectures-and-training-paradigms"><i class="fa fa-check"></i><b>4.1.6</b> Combining General Architectures and Training Paradigms</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="further-topics.html"><a href="further-topics.html#strucutered-unstrucutered-data"><i class="fa fa-check"></i><b>4.2</b> Strucutered + Unstrucutered Data</a><ul>
<li class="chapter" data-level="4.2.1" data-path="further-topics.html"><a href="further-topics.html#intro-2"><i class="fa fa-check"></i><b>4.2.1</b> Intro</a></li>
<li class="chapter" data-level="4.2.2" data-path="further-topics.html"><a href="further-topics.html#taxonomy-structured-vs.-unstructured-data"><i class="fa fa-check"></i><b>4.2.2</b> Taxonomy: Structured vs. Unstructured Data</a></li>
<li class="chapter" data-level="4.2.3" data-path="further-topics.html"><a href="further-topics.html#fusion-strategies"><i class="fa fa-check"></i><b>4.2.3</b> Fusion Strategies</a></li>
<li class="chapter" data-level="4.2.4" data-path="further-topics.html"><a href="further-topics.html#applications-of-multimodal-dl"><i class="fa fa-check"></i><b>4.2.4</b> Applications of Multimodal DL</a></li>
<li class="chapter" data-level="4.2.5" data-path="further-topics.html"><a href="further-topics.html#multimodal-dl-in-survival"><i class="fa fa-check"></i><b>4.2.5</b> Multimodal DL in Survival</a></li>
<li class="chapter" data-level="4.2.6" data-path="further-topics.html"><a href="further-topics.html#traditional-survival-analysis-cox-proportional-hazard-model"><i class="fa fa-check"></i><b>4.2.6</b> Traditional Survival Analysis (Cox Proportional Hazard Model)</a></li>
<li class="chapter" data-level="4.2.7" data-path="further-topics.html"><a href="further-topics.html#deepconvsurvdeepcorrsurv"><i class="fa fa-check"></i><b>4.2.7</b> DeepConvSurv+DeepCorrSurv</a></li>
<li class="chapter" data-level="4.2.8" data-path="further-topics.html"><a href="further-topics.html#concat-cross-auto-encoders"><i class="fa fa-check"></i><b>4.2.8</b> Concat + Cross Auto Encoders</a></li>
<li class="chapter" data-level="4.2.9" data-path="further-topics.html"><a href="further-topics.html#cheerla-and-gevaert-2019"><i class="fa fa-check"></i><b>4.2.9</b> Cheerla and Gevaert (2019)</a></li>
<li class="chapter" data-level="4.2.10" data-path="further-topics.html"><a href="further-topics.html#multimodal-dl-in-economics"><i class="fa fa-check"></i><b>4.2.10</b> Multimodal DL in Economics</a></li>
<li class="chapter" data-level="4.2.11" data-path="further-topics.html"><a href="further-topics.html#critical-assessment"><i class="fa fa-check"></i><b>4.2.11</b> Critical Assessment</a></li>
<li class="chapter" data-level="4.2.12" data-path="further-topics.html"><a href="further-topics.html#conclusion-and-outlook"><i class="fa fa-check"></i><b>4.2.12</b> Conclusion and Outlook</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="further-topics.html"><a href="further-topics.html#multi-purpose-models"><i class="fa fa-check"></i><b>4.3</b> Multi-purpose Models</a><ul>
<li class="chapter" data-level="4.3.1" data-path="further-topics.html"><a href="further-topics.html#intro-3"><i class="fa fa-check"></i><b>4.3.1</b> Intro</a></li>
<li class="chapter" data-level="4.3.2" data-path="further-topics.html"><a href="further-topics.html#introduction-1"><i class="fa fa-check"></i><b>4.3.2</b> Introduction</a></li>
<li class="chapter" data-level="4.3.3" data-path="further-topics.html"><a href="further-topics.html#todo-1"><i class="fa fa-check"></i><b>4.3.3</b> TODO</a></li>
<li class="chapter" data-level="4.3.4" data-path="further-topics.html"><a href="further-topics.html#previous-work"><i class="fa fa-check"></i><b>4.3.4</b> Previous Work</a></li>
<li class="chapter" data-level="4.3.5" data-path="further-topics.html"><a href="further-topics.html#todo-2"><i class="fa fa-check"></i><b>4.3.5</b> TODO</a></li>
<li class="chapter" data-level="4.3.6" data-path="further-topics.html"><a href="further-topics.html#pathway-proposal"><i class="fa fa-check"></i><b>4.3.6</b> Pathway Proposal</a></li>
<li class="chapter" data-level="4.3.7" data-path="further-topics.html"><a href="further-topics.html#todo-3"><i class="fa fa-check"></i><b>4.3.7</b> TODO</a></li>
<li class="chapter" data-level="4.3.8" data-path="further-topics.html"><a href="further-topics.html#discussion-1"><i class="fa fa-check"></i><b>4.3.8</b> Discussion</a></li>
<li class="chapter" data-level="4.3.9" data-path="further-topics.html"><a href="further-topics.html#todo-4"><i class="fa fa-check"></i><b>4.3.9</b> TODO</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="title.html"><a href="title.html"><i class="fa fa-check"></i><b>5</b> title</a></li>
<li class="chapter" data-level="6" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>6</b> Conclusion</a><ul>
<li class="chapter" data-level="6.0.1" data-path="conclusion.html"><a href="conclusion.html#header13-03-04-usecase"><i class="fa fa-check"></i><b>6.0.1</b> Header13 {#03-04-usecase}</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="epilogue.html"><a href="epilogue.html"><i class="fa fa-check"></i><b>7</b> Epilogue</a></li>
<li class="chapter" data-level="8" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>8</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multimodal Deep Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="conclusion" class="section level1 hasAnchor">
<h1><span class="header-section-number">Chapter 6</span> Conclusion<a href="conclusion.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Author: Nadja Sauter</em></p>
<p><em>Supervisor: Matthias Assenmacher</em></p>
<p>It is very impressive how multimodal architectures developed especially over the course of the last two years. Particularly, methods to generate pictures based on text prompts like DALL-E became incredibly good in their job. A lot of people are fascinated by the stunning results and a huge hype about these AI generated images evolved in the internet, especially on twitter. In this way, the models were not only investigated by researchers but also by the AI online Community (e.g. Katherine Crowson alias <a href="https://twitter.com/RiversHaveWings">Rivers Have Wings</a>). Even in the art scene these methods attracted a lot of attention as shown in our use case “Generative Arts” (subsection <a href="#03-04-usecase"><strong>??</strong></a>). Apart from that, it is possible to deploy these methods commercially, for instance in the film production or gaming industry (e.g. creating characters for games). However, this also results into problems of copyright.</p>
<p>It is impressive how realistic and precise outputs are achieved by such architectures. On the other hand, these methods can also be abused to spread misleading information as it is often very difficult to distinguish between a fake or a real picture by only looking at it. This can be systematically used to manipulate the public opinion by spreading AI manipulated media, also called deep fakes. That’s why researchers like <span class="citation">(<span class="citeproc-not-found" data-reference-id="explainaility"><strong>???</strong></span>)</span> demand automated tools which are capable of detecting these fabrications. Apart from taht, like most Deep Learning models, multimodal architectures are not free from bias which also needs to be investigated further <span class="citation">(<span class="citeproc-not-found" data-reference-id="bias"><strong>???</strong></span>)</span>. Besides, the algorithms are very complex which is why they are called “black-box” models, meaning that one cannot directly retrace how the model came to a certain solution or decision. This may limit their social acceptance and usability as the underlying process is not credible and transparent enough <span class="citation">(<span class="citeproc-not-found" data-reference-id="explainaility"><strong>???</strong></span>)</span>. For instance, in medical applications like e.g. predicting the presence or absence of cancer, apart from the decision of the AI the reasoning and the certainty are highly relevant for doctors and patients.</p>
<p>Furthermore, there is a clear trend in recent years to build more and more complex architectures in order to achieve higher performance. For instance OpenAI’s language model GPT-2 has about 1.5 Billion parameter <span class="citation">(<span class="citeproc-not-found" data-reference-id="Radford2019LanguageMA"><strong>???</strong></span>)</span> whereas its successor GPT-3 has about 175 Billion parameters <span class="citation">(<span class="citeproc-not-found" data-reference-id="GPT3"><strong>???</strong></span>)</span>. Increasing the number of parameters often helps to improve model performance, but all of these parameters need to be trained and stored which takes a lot of time, enormous computational power and storage. For example, training GPT-2 took about one week (168 hours) of training on 32 TPUv3 chips <span class="citation">(<span class="citeproc-not-found" data-reference-id="environment"><strong>???</strong></span>)</span>. The researchers <span class="citation">(<span class="citeproc-not-found" data-reference-id="environment"><strong>???</strong></span>)</span> estimated that the cloud compute costs for training GPT-2 add up to about $12,902–$43,008. Apart from the enormous expenses, this also contributes to our environmental burden as this process is really energy intensive. Due to missing power draw data on GPT-2’s training hardware, the researchers weren’t able to calculate the CO<sub>2</sub> emission. However, for the popular BERT architecture with 110M parameters they calculated cloud compute costs of $3,751-$12,571, energy consumption of 1,507 kWh and a Carbon footprint of 1,438 lbs of CO<sub>2</sub>. In comparison, the footprint of flying from New York to San Francisco by plane for one passenger is about 1,984 lbs of CO<sub>2</sub>. In conclusion training BERT once results in almost the same footprint as this long-haul flight. On top of this, these numbers are only for one training run. Developing a new model or adapting it often takes several fitting and tuning phases.</p>
<p>Moreover, the computational power as well as the necessary hardware, technology and financial means to run these models can only be provided by big technology companies like e.g. Google, Facebook or Open AI. This results in a disparate access between researchers in academia versus industry. Furthermore, the companies often do not publish their models as they are their ‘product’ and intellectual property. In this way it is not possible to reproduce their work and findings independently. Besides, from an economic point of view, this may be the foundation of a monopoly which can be dangerous for economic competition and could abused by the Tech Giants.</p>
<div id="header13-03-04-usecase" class="section level3 hasAnchor">
<h3><span class="header-section-number">6.0.1</span> Header13 {#03-04-usecase}<a href="conclusion.html#header13-03-04-usecase" class="anchor-section" aria-label="Anchor link to header"></a></h3>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="title.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="epilogue.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["book.pdf", "book.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
