@MANUAL{rlang,
  AUTHOR = {{R Core Team}},
  ORGANIZATION = {R Foundation for Statistical Computing},
  URL = {https://www.R-project.org/},
  DATE = {2018},
  TITLE = {R: A Language and Environment for Statistical Computing},
}

@INPROCEEDINGS{cornia2020m2,
  AUTHOR = {Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  DATE = {2020},
  TITLE = {{Meshed-Memory Transformer for Image Captioning}},
}

@ARTICLE{bordes2020incorporating,
  AUTHOR = {Bordes, Patrick and Zablocki, Eloi and Soulier, Laure and Piwowarski, Benjamin and Gallinari, Patrick},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2002.02734},
  TITLE = {Incorporating visual semantics into sentence representations within a grounded space},
}

@ARTICLE{harnad1990symbol,
  AUTHOR = {Harnad, Stevan},
  PUBLISHER = {Elsevier},
  DATE = {1990},
  JOURNALTITLE = {Physica D: Nonlinear Phenomena},
  NUMBER = {1-3},
  PAGES = {335--346},
  TITLE = {The symbol grounding problem},
  VOLUME = {42},
}

@INPROCEEDINGS{mccoco,
  AUTHOR = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C. Lawrence},
  PUBLISHER = {Springer International Publishing},
  BOOKTITLE = {Computer Vision -- ECCV 2014},
  DATE = {2014},
  ISBN = {978-3-319-10602-1},
  PAGES = {740--755},
  TITLE = {Microsoft COCO: Common Objects in Context},
}

@INPROCEEDINGS{radford2021learning,
  AUTHOR = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International Conference on Machine Learning},
  DATE = {2021},
  PAGES = {8748--8763},
  TITLE = {Learning transferable visual models from natural language supervision},
}

@INPROCEEDINGS{silberer2012grounded,
  AUTHOR = {Silberer, Carina and Lapata, Mirella},
  ORGANIZATION = {ACL (Association for Computational Linguistics)},
  BOOKTITLE = {Tsujii J, Henderson J, Paşca M, editors. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning; 2012 Jul 12--14; Jeju Island, Korea. Stroudsburg: ACL; 2012. p. 1423-33.},
  DATE = {2012},
  TITLE = {Grounded models of semantic representation},
}

@ARTICLE{baevski2022data2vec,
  AUTHOR = {Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2202.03555},
  TITLE = {Data2vec: A general framework for self-supervised learning in speech, vision and language},
}

@ARTICLE{vaswani2017attention,
  AUTHOR = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {Ł}ukasz and Polosukhin, Illia},
  DATE = {2017},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Attention is all you need},
  VOLUME = {30},
}

@ARTICLE{dosovitskiy2020image,
  AUTHOR = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.11929},
  TITLE = {An image is worth 16x16 words: Transformers for image recognition at scale},
}

@ARTICLE{alayrac2022flamingo,
  AUTHOR = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and others},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.14198},
  TITLE = {Flamingo: a visual language model for few-shot learning},
}

@ARTICLE{lu2019vilbert,
  AUTHOR = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  DATE = {2019},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
  VOLUME = {32},
}

@ARTICLE{uppal2022multimodal,
  AUTHOR = {Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumder, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir},
  PUBLISHER = {Elsevier},
  DATE = {2022},
  JOURNALTITLE = {Information Fusion},
  PAGES = {149--171},
  TITLE = {Multimodal research in vision and language: A review of current and emerging trends},
  VOLUME = {77},
}

@INPROCEEDINGS{ramesh2021dalle,
  AUTHOR = {Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  PUBLISHER = {PMLR},
  URL = {https://proceedings.mlr.press/v139/ramesh21a.html},
  BOOKTITLE = {Proceedings of the 38th International Conference on Machine Learning},
  DATE = {2021-06},
  FILE = {http://proceedings.mlr.press/v139/ramesh21a/ramesh21a.pdf},
  PAGES = {8821--8831},
  SERIES = {Proceedings of Machine Learning Research},
  TITLE = {Zero-Shot Text-to-Image Generation},
  VOLUME = {139},
}

@ARTICLE{nichol2021glide,
  AUTHOR = {Nichol, Alex and Dhariwal, Prafulla and Ramesh, Aditya and Shyam, Pranav and Mishkin, Pamela and McGrew, Bob and Sutskever, Ilya and Chen, Mark},
  URL = {https://arxiv.org/abs/2112.10741},
  DATE = {2021},
  EPRINT = {2112.10741},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {{GLIDE:} Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models},
}

@ARTICLE{HuangFusion2020,
  AUTHOR = {Huang, Shih-Cheng and Pareek, Anuj and Seyyedi, Saeed and Banerjee, Imon and Lungren, Matthew},
  DATE = {2020-12},
  DOI = {10.1038/s41746-020-00341-z},
  JOURNALTITLE = {npj Digital Medicine},
  TITLE = {Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines},
  VOLUME = {3},
}

@article{Katzman2018,
author = {Katzman, Jared and Shaham, Uri and Cloninger, Alexander and Bates, Jonathan and Jiang, Tingting and Kluger, Yuval},
year = {2018},
month = {02},
pages = {},
title = {DeepSurv: Personalized treatment recommender system using a Cox proportional hazards deep neural network},
volume = {18},
journal = {BMC Medical Research Methodology},
doi = {10.1186/s12874-018-0482-1}
}

@INPROCEEDINGS{DeepConvSurv,
  AUTHOR = {Zhu, Xinliang and Yao, Jiawen and Huang, Junzhou},
  BOOKTITLE = {2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
  DATE = {2016},
  DOI = {10.1109/BIBM.2016.7822579},
  PAGES = {544--547},
  TITLE = {Deep convolutional neural network for survival analysis with pathological images},
}

@INPROCEEDINGS{DeepCorrSurv,
  AUTHOR = {Yao, Jiawen and Zhu, Xinliang and Zhu, Feiyun and Huang, Junzhou},
  PUBLISHER = {Springer International Publishing},
  BOOKTITLE = {Medical Image Computing and Computer-Assisted Intervention − MICCAI 2017},
  DATE = {2017},
  ISBN = {978-3-319-66185-8},
  PAGES = {406--414},
  TITLE = {Deep Correlational Learning for Survival Prediction from Multi-modality Data},
}

@article{TongAE,
author = {Tong, Li and Mitchel, Jonathan and Chatlin, Kevin and Wang, May},
year = {2020},
month = {09},
pages = {225},
title = {Deep learning based feature-level integration of multi-omics data for breast cancer patients survival analysis},
volume = {20},
journal = {BMC medical informatics and decision making},
doi = {10.1186/s12911-020-01225-8}
}

@article{Cheerla2019,
author = {Cheerla, Anika and Gevaert, Olivier},
year = {2019},
month = {07},
pages = {i446-i454},
title = {Deep learning with multimodal representation for pancancer prognosis prediction},
volume = {35},
journal = {Bioinformatics (Oxford, England)},
doi = {10.1093/bioinformatics/btz342}
}

@article{MultiSurv2021,
author = {Vale-Silva, Luís and Rohr, Karl},
year = {2021},
month = {06},
pages = {13505},
title = {Long-term cancer survival prediction using multimodal deep learning},
volume = {11},
journal = {Scientific Reports},
doi = {10.1038/s41598-021-92799-4}
}

@ARTICLE{DeepPAMM2022,
  AUTHOR = {Kopper, Philipp and Wiegrebe, Simon and Bischl, Bernd and Bender, Andreas and Rügamer, David},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2202.07423},
  DATE = {2022},
  DOI = {10.48550/ARXIV.2202.07423},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex Hazard Structures in Survival Analysis},
}

@misc{WideDeepNN2016,
  doi = {10.48550/ARXIV.1606.07792},
  url = {https://arxiv.org/abs/1606.07792},
  author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
  title = {Wide and Deep Learning for Recommender Systems},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@ARTICLE{Poelsterl2020,
  AUTHOR = {Pölsterl, Sebastian and Sarasua, Ignacio and Gutiérrez{-}Becker, Benjamı́n and Wachinger, Christian},
  URL = {http://arxiv.org/abs/1909.03890},
  DATE = {2019},
  EPRINT = {1909.03890},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {A Wide and Deep Neural Network for Survival Analysis from Anatomical Shape and Tabular Clinical Data},
}

@MISC{SSDDR2020,
  AUTHOR = {Rügamer, David and Kolb, Chris and Klein, Nadja},
  PUBLISHER = {arXiv},
  URL = {https://arxiv.org/abs/2002.05777},
  DATE = {2020},
  DOI = {10.48550/ARXIV.2002.05777},
  KEYWORDS = {Machine Learning (stat.ML),Machine Learning (cs.LG),Methodology (stat.ME),FOS: Computer and information sciences,FOS: Computer and information sciences},
  TITLE = {Semi-Structured Distributional Regression -- Extending Structured Additive Models by Arbitrary Deep Neural Networks and Data Modalities},
}

@ARTICLE{Law2019,
  AUTHOR = {Law, Stephen and Paige, Brooks and Russell, Chris},
  PUBLISHER = {Association for Computing Machinery ({ACM})},
  URL = {https://doi.org/10.1145%2F3342240},
  DATE = {2019-09},
  DOI = {10.1145/3342240},
  JOURNALTITLE = {{ACM} Transactions on Intelligent Systems and Technology},
  NUMBER = {5},
  PAGES = {1--19},
  TITLE = {Take a Look Around},
  VOLUME = {10},
}

@ARTICLE{Jean2016,
  AUTHOR = {Jean, Neal and Burke, Marshall and Xie, Michael and Davis, W. Matthew and Lobell, David B. and Ermon, Stefano},
  URL = {https://www.science.org/doi/abs/10.1126/science.aaf7894},
  DATE = {2016},
  DOI = {10.1126/science.aaf7894},
  EPRINT = {https://www.science.org/doi/pdf/10.1126/science.aaf7894},
  JOURNALTITLE = {Science},
  NUMBER = {6301},
  PAGES = {790--794},
  TITLE = {Combining satellite imagery and machine learning to predict poverty},
  VOLUME = {353},
}

@article{Gebru2017,
author = {Gebru, Timnit and Krause, Jonathan and Wang, Yilun and Chen, Duyun and Deng, Jia and Aiden, Erez and Fei-Fei, Li},
year = {2017},
month = {11},
pages = {201700035},
title = {Using deep learning and Google Street View to estimate the demographic makeup of neighborhoods across the United States},
volume = {114},
journal = {Proceedings of the National Academy of Sciences},
doi = {10.1073/pnas.1700035114}
}

@INPROCEEDINGS{DeepGPYou2017,
  AUTHOR = {You, Jiaxuan and Li, Xiaocheng and Low, Melvin and Lobell, David and Ermon, Stefano},
  LOCATION = {San Francisco, California, USA},
  PUBLISHER = {AAAI Press},
  BOOKTITLE = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
  DATE = {2017},
  PAGES = {4559--4565},
  SERIES = {AAAI'17},
  TITLE = {Deep Gaussian Process for Crop Yield Prediction Based on Remote Sensing Data},
}

@ARTICLE{Sirko2021,
  AUTHOR = {Sirko, Wojciech and Kashubin, Sergii and Ritter, Marvin and Annkah, Abigail and Bouchareb, Yasser Salah Eddine and Dauphin, Yann N. and Keysers, Daniel and Neumann, Maxim and Cissé, Moustapha and Quinn, John},
  URL = {https://arxiv.org/abs/2107.12283},
  DATE = {2021},
  EPRINT = {2107.12283},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Continental-Scale Building Detection from High Resolution Satellite Imagery},
}

@ARTICLE{bommasani2021opportunities,
  AUTHOR = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  DATE = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2108.07258},
  TITLE = {On the opportunities and risks of foundation models},
}

@ARTICLE{yuan2021florence,
  AUTHOR = {Yuan, Lu and Chen, Dongdong and Chen, Yi-Ling and Codella, Noel and Dai, Xiyang and Gao, Jianfeng and Hu, Houdong and Huang, Xuedong and Li, Boxin and Li, Chunyuan and others},
  DATE = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2111.11432},
  TITLE = {Florence: A New Foundation Model for Computer Vision},
}

@ARTICLE{ramesh2022hierarchical,
  AUTHOR = {Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2204.06125},
  TITLE = {Hierarchical Text-Conditional Image Generation with CLIP Latents. 2022},
}

@ARTICLE{zhang2020contrastive,
  AUTHOR = {Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.00747},
  TITLE = {Contrastive learning of medical visual representations from paired images and text},
}

@ONLINE{sutton2019bitterlesson,
  AUTHOR = {Sutton, R. S.},
  URL = {http://www.incompleteideas.net/IncIdeas/BitterLesson.htwml},
  DATE = {2019-03-13},
  TITLE = {The Bitter Lesson},
}

@ONLINE{openai2021clipblog,
  AUTHOR = {OpenAI},
  URL = {https://openai.com/blog/clip/},
  DATE = {2021-01-05},
  TITLE = {CLIP: Connection Text and Images},
}

@ONLINE{alford2021alignparams,
  AUTHOR = {Alford, A.},
  URL = {https://www.infoq.com/news/2021/07/google-vision-language-ai/},
  DATE = {2021-07-20},
  TITLE = {Google Announces 800M Parameter Vision-Language AI Model ALIGN},
}

@ONLINE{schuhmann2022laion,
  AUTHOR = {Schuhmann, C.},
  URL = {https://laion.ai/blog/laion-400-open-dataset/},
  DATE = {2022-07-07},
  TITLE = {Laion-400-Million Open Dataset},
}

@ONLINE{solawetz2021florenceopen,
  AUTHOR = {Solawetz, J.},
  URL = {https://blog.roboflow.com/florence-a-new-foundational-model-for-computer-vision/},
  DATE = {2021-12-09},
  TITLE = {Florence: A New Foundation for Computer Vision},
}

@INPROCEEDINGS{jia2021scaling,
  AUTHOR = {Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International Conference on Machine Learning},
  DATE = {2021},
  PAGES = {4904--4916},
  TITLE = {Scaling up visual and vision-language representation learning with noisy text supervision},
}

@INPROCEEDINGS{tian2020contrastive,
  AUTHOR = {Tian, Yonglong and Krishnan, Dilip and Isola, Phillip},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  DATE = {2020},
  PAGES = {776--794},
  TITLE = {Contrastive multiview coding},
}

@ARTICLE{yu2022coca,
  AUTHOR = {Yu, Jiahui and Wang, Zirui and Vasudevan, Vijay and Yeung, Legg and Seyedhosseini, Mojtaba and Wu, Yonghui},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2205.01917},
  TITLE = {CoCa: Contrastive Captioners are Image-Text Foundation Models},
}

@ARTICLE{Mikolov2013,
  AUTHOR = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  DATE = {2013-01-16},
  EPRINT = {1301.3781},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1301.3781v3:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {Efficient Estimation of Word Representations in Vector Space},
}

@ARTICLE{brown2020language,
  AUTHOR = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  DATE = {2020},
  JOURNALTITLE = {Advances in neural information processing systems},
  PAGES = {1877--1901},
  TITLE = {Language models are few-shot learners},
  VOLUME = {33},
}

@ARTICLE{Bojanowski2016,
  AUTHOR = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  DATE = {2016-07-15},
  EPRINT = {1607.04606},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1607.04606v2:PDF},
  KEYWORDS = {cs.CL,cs.LG},
  TITLE = {Enriching Word Vectors with Subword Information},
}

@ARTICLE{Bahdanau2014,
  AUTHOR = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  DATE = {2014-09-01},
  EPRINT = {1409.0473},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1409.0473v7:PDF},
  KEYWORDS = {cs.CL,cs.LG,cs.NE,stat.ML},
  TITLE = {Neural Machine Translation by Jointly Learning to Align and Translate},
}

@ARTICLE{Sutskever2014,
  AUTHOR = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
  DATE = {2014-09-10},
  EPRINT = {1409.3215},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1409.3215v3:PDF},
  KEYWORDS = {cs.CL,cs.LG},
  TITLE = {Sequence to Sequence Learning with Neural Networks},
}

@ARTICLE{Devlin2018,
  AUTHOR = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  DATE = {2018-10-11},
  EPRINT = {1810.04805},
  EPRINTCLASS = {cs.CL},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1810.04805v2:PDF},
  KEYWORDS = {cs.CL},
  TITLE = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
}

@ARTICLE{Raffel2019,
  AUTHOR = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  DATE = {2019-10-23},
  EPRINT = {1910.10683},
  EPRINTCLASS = {cs.LG},
  EPRINTTYPE = {arXiv},
  FILE = {:http\://arxiv.org/pdf/1910.10683v3:PDF},
  KEYWORDS = {cs.LG,cs.CL,stat.ML},
  TITLE = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
}

@ARTICLE{ResNet,
  AUTHOR = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  URL = {http://arxiv.org/abs/1512.03385},
  DATE = {2015},
  EPRINT = {1512.03385},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Deep Residual Learning for Image Recognition},
}

@ARTICLE{EfficientNet,
  AUTHOR = {Tan, Mingxing and Le, Quoc V.},
  URL = {http://arxiv.org/abs/1905.11946},
  DATE = {2019},
  EPRINT = {1905.11946},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
}

@ARTICLE{SimCLR,
  AUTHOR = {Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey E.},
  URL = {https://arxiv.org/abs/2002.05709},
  DATE = {2020},
  EPRINT = {2002.05709},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {A Simple Framework for Contrastive Learning of Visual Representations},
}

@ARTICLE{SwAV,
  AUTHOR = {Caron, Mathilde and Misra, Ishan and Mairal, Julien and Goyal, Priya and Bojanowski, Piotr and Joulin, Armand},
  URL = {https://arxiv.org/abs/2006.09882},
  DATE = {2020},
  EPRINT = {2006.09882},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Unsupervised Learning of Visual Features by Contrasting Cluster Assignments},
}

@ARTICLE{BYOL,
  AUTHOR = {Grill, Jean{-}Bastien and Strub, Florian and Altché, Florent and Tallec, Corentin and Richemond, Pierre H. and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Ávila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and Piot, Bilal and Kavukcuoglu, Koray and Munos, Rémi and Valko, Michal},
  URL = {https://arxiv.org/abs/2006.07733},
  DATE = {2020},
  EPRINT = {2006.07733},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {Bootstrap Your Own Latent: {A} New Approach to Self-Supervised Learning},
}

@ARTICLE{ImageT,
  AUTHOR = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  URL = {https://arxiv.org/abs/2010.11929},
  DATE = {2020},
  EPRINT = {2010.11929},
  EPRINTTYPE = {arXiv},
  JOURNALTITLE = {CoRR},
  TITLE = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
}

@INPROCEEDINGS{he2022masked,
  AUTHOR = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Dollár, Piotr and Girshick, Ross},
  BOOKTITLE = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  DATE = {2022},
  PAGES = {16000--16009},
  TITLE = {Masked autoencoders are scalable vision learners},
}

@ARTICLE{rosset2020turing,
  AUTHOR = {Rosset, Corby},
  DATE = {2020},
  JOURNALTITLE = {Microsoft Blog},
  NUMBER = {2},
  TITLE = {Turing-NLG: A 17-billion-parameter language model by Microsoft},
  VOLUME = {1},
}

@ARTICLE{gao2020pile,
  AUTHOR = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and others},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2101.00027},
  TITLE = {The pile: An 800gb dataset of diverse text for language modeling},
}

@INPROCEEDINGS{zhu2015aligning,
  AUTHOR = {Zhu, Yukun and Kiros, Ryan and Zemel, Rich and Salakhutdinov, Ruslan and Urtasun, Raquel and Torralba, Antonio and Fidler, Sanja},
  BOOKTITLE = {Proceedings of the IEEE international conference on computer vision},
  DATE = {2015},
  PAGES = {19--27},
  TITLE = {Aligning books and movies: Towards story-like visual explanations by watching movies and reading books},
}

@INCOLLECTION{fellbaum2010wordnet,
  AUTHOR = {Fellbaum, Christiane},
  PUBLISHER = {Springer},
  BOOKTITLE = {Theory and applications of ontology: computer applications},
  DATE = {2010},
  PAGES = {231--243},
  TITLE = {WordNet},
}

@ARTICLE{krizhevsky2009learning,
  AUTHOR = {Krizhevsky, Alex and Hinton, Geoffrey and others},
  PUBLISHER = {Toronto, ON, Canada},
  DATE = {2009},
  TITLE = {Learning multiple layers of features from tiny images},
}

@INPROCEEDINGS{deng2009imagenet,
  AUTHOR = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  ORGANIZATION = {Ieee},
  BOOKTITLE = {2009 IEEE conference on computer vision and pattern recognition},
  DATE = {2009},
  PAGES = {248--255},
  TITLE = {Imagenet: A large-scale hierarchical image database},
}

@ARTICLE{hinton2015distilling,
  AUTHOR = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
  DATE = {2015},
  JOURNALTITLE = {arXiv preprint arXiv:1503.02531},
  NUMBER = {7},
  TITLE = {Distilling the knowledge in a neural network},
  VOLUME = {2},
}

@INPROCEEDINGS{sun2017revisiting,
  AUTHOR = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  BOOKTITLE = {Proceedings of the IEEE international conference on computer vision},
  DATE = {2017},
  PAGES = {843--852},
  TITLE = {Revisiting unreasonable effectiveness of data in deep learning era},
}

@ARTICLE{schuhmann2021laion,
  AUTHOR = {Schuhmann, Christoph and Vencu, Richard and Beaumont, Romain and Kaczmarczyk, Robert and Mullis, Clayton and Katta, Aarush and Coombes, Theo and Jitsev, Jenia and Komatsuzaki, Aran},
  DATE = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2111.02114},
  TITLE = {Laion-400m: Open dataset of clip-filtered 400 million image-text pairs},
}

@INPROCEEDINGS{lin2014microsoft,
  AUTHOR = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Dollár, Piotr and Zitnick, C Lawrence},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  DATE = {2014},
  PAGES = {740--755},
  TITLE = {Microsoft coco: Common objects in context},
}

@INPROCEEDINGS{torralba2011unbiased,
  AUTHOR = {Torralba, Antonio and Efros, Alexei A},
  ORGANIZATION = {IEEE},
  BOOKTITLE = {CVPR 2011},
  DATE = {2011},
  PAGES = {1521--1528},
  TITLE = {Unbiased look at dataset bias},
}

@INPROCEEDINGS{pont2020connecting,
  AUTHOR = {Pont-Tuset, Jordi and Uijlings, Jasper and Changpinyo, Soravit and Soricut, Radu and Ferrari, Vittorio},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  DATE = {2020},
  PAGES = {647--664},
  TITLE = {Connecting vision and language with localized narratives},
}

@INPROCEEDINGS{zhou2017scene,
  AUTHOR = {Zhou, Bolei and Zhao, Hang and Puig, Xavier and Fidler, Sanja and Barriuso, Adela and Torralba, Antonio},
  BOOKTITLE = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  DATE = {2017},
  PAGES = {633--641},
  TITLE = {Scene parsing through ade20k dataset},
}

@ARTICLE{young2014image,
  AUTHOR = {Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  PUBLISHER = {MIT Press},
  DATE = {2014},
  JOURNALTITLE = {Transactions of the Association for Computational Linguistics},
  PAGES = {67--78},
  TITLE = {From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  VOLUME = {2},
}

@ARTICLE{kuznetsova2020open,
  AUTHOR = {Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Kolesnikov, Alexander and others},
  PUBLISHER = {Springer},
  DATE = {2020},
  JOURNALTITLE = {International Journal of Computer Vision},
  NUMBER = {7},
  PAGES = {1956--1981},
  TITLE = {The open images dataset v4},
  VOLUME = {128},
}

@ONLINE{LocNarWeb,
  AUTHOR = {Website},
  URL = {https://google.github.io/localized-narratives},
  DATE = {2020},
  TITLE = {Localized Narratives Data and Visualization},
  URLDATE = {2022-06-26},
}

@ARTICLE{krishna2017visual,
  AUTHOR = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A and others},
  PUBLISHER = {Springer},
  DATE = {2017},
  JOURNALTITLE = {International journal of computer vision},
  NUMBER = {1},
  PAGES = {32--73},
  TITLE = {Visual genome: Connecting language and vision using crowdsourced dense image annotations},
  VOLUME = {123},
}

@ARTICLE{saharia2022photorealistic,
  AUTHOR = {Saharia, Chitwan and Chan, William and Saxena, Saurabh and Li, Lala and Whang, Jay and Denton, Emily and Ghasemipour, Seyed Kamyar Seyed and Ayan, Burcu Karagol and Mahdavi, S Sara and Lopes, Rapha Gontijo and others},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2205.11487},
  TITLE = {Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding},
}

@ARTICLE{parti,
  AUTHOR = {Yu, Jiahui and Xu, Yuanzhong and Koh, Jing and Luong, Thang and Baid, Gunjan and Vasudevan, Vijay and Ku, Alexander and Yang, Yinfei and Ayan, Burcu and Hutchinson, Ben and Han, Wei and Parekh, Zarana and Li, Xin and Zhang, Han and Baldridge, Jason and Wu, Yonghui},
  DATE = {2022-06},
  DOI = {10.48550/arXiv.2206.10789},
  TITLE = {Scaling Autoregressive Models for Content-Rich Text-to-Image Generation},
}

@ONLINE{darkMatter,
  AUTHOR = {Yann, Lecun and Ishan, Misra},
  URL = {https://ai.facebook.com/blog/self-supervised-learning-the-dark-matter-of-intelligence/},
  DATE = {2021},
  TITLE = {Self-supervised learning: The dark matter of intelligence},
  URLDATE = {2022-06-26},
}

@ONLINE{redditUsers,
  AUTHOR = {MICHAEL BARTHEL, GALEN STOCKING, JESSE HOLCOMB and MITCHELL, AMY},
  URL = {https://www.pewresearch.org/journalism/2016/02/25/reddit-news-users-more-likely-to-be-male-young-and-digital-in-their-news-preferences/},
  DATE = {2016},
  TITLE = {Reddit news users more likely to be male, young and digital in their news preferences},
  URLDATE = {2022-08-07},
}

@ONLINE{coco_eval,
  AUTHOR = {Mircosoft},
  URL = {https://cocodataset.org/#detection-eval},
  DATE = {2019},
  TITLE = {Evaluate:Detection},
  URLDATE = {2022-07-09},
}

@ONLINE{unsupBrain,
  AUTHOR = {Mineault, Patrick},
  URL = {https://xcorr.net/2021/12/31/2021-in-review-unsupervised-brain-models/},
  DATE = {2021},
  TITLE = {Unsupervised models of the brain},
  URLDATE = {2022-06-26},
}

@ARTICLE{zhuang2021unsupervised,
  AUTHOR = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C and DiCarlo, James J and Yamins, Daniel LK},
  PUBLISHER = {National Acad Sciences},
  DATE = {2021},
  JOURNALTITLE = {Proceedings of the National Academy of Sciences},
  NUMBER = {3},
  PAGES = {e2014196118},
  TITLE = {Unsupervised neural network models of the ventral visual stream},
  VOLUME = {118},
}

@ARTICLE{liu2019roberta,
  AUTHOR = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  DATE = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1907.11692},
  TITLE = {Roberta: A robustly optimized bert pretraining approach},
}

@ARTICLE{bromley1993signature,
  AUTHOR = {Bromley, Jane and Guyon, Isabelle and LeCun, Yann and Säckinger, Eduard and Shah, Roopak},
  DATE = {1993},
  JOURNALTITLE = {Advances in neural information processing systems},
  TITLE = {Signature verification using a" siamese" time delay neural network},
  VOLUME = {6},
}

@ARTICLE{grill2020bootstrap,
  AUTHOR = {Grill, Jean-Bastien and Strub, Florian and Altché, Florent and Tallec, Corentin and Richemond, Pierre and Buchatskaya, Elena and Doersch, Carl and Avila Pires, Bernardo and Guo, Zhaohan and Gheshlaghi Azar, Mohammad and others},
  DATE = {2020},
  JOURNALTITLE = {Advances in neural information processing systems},
  PAGES = {21271--21284},
  TITLE = {Bootstrap your own latent-a new approach to self-supervised learning},
  VOLUME = {33},
}

@INPROCEEDINGS{caron2021emerging,
  AUTHOR = {Caron, Mathilde and Touvron, Hugo and Misra, Ishan and Jégou, Hervé and Mairal, Julien and Bojanowski, Piotr and Joulin, Armand},
  BOOKTITLE = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
  DATE = {2021},
  PAGES = {9650--9660},
  TITLE = {Emerging properties in self-supervised vision transformers},
}

@INPROCEEDINGS{mahajan2018exploring,
  AUTHOR = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and Van Der Maaten, Laurens},
  BOOKTITLE = {Proceedings of the European conference on computer vision (ECCV)},
  DATE = {2018},
  PAGES = {181--196},
  TITLE = {Exploring the limits of weakly supervised pretraining},
}

@ARTICLE{kolesnikov2019large,
  AUTHOR = {Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Puigcerver, Joan and Yung, Jessica and Gelly, Sylvain and Houlsby, Neil},
  PUBLISHER = {arXiv},
  DATE = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1912.11370},
  NUMBER = {8},
  TITLE = {Large scale learning of general visual representations for transfer},
  VOLUME = {2},
}

@ARTICLE{rajpurkar2016squad,
  AUTHOR = {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
  DATE = {2016},
  JOURNALTITLE = {arXiv preprint arXiv:1606.05250},
  TITLE = {Squad: 100,000+ questions for machine comprehension of text},
}

@ARTICLE{rajpurkar2018know,
  AUTHOR = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  DATE = {2018},
  JOURNALTITLE = {arXiv preprint arXiv:1806.03822},
  TITLE = {Know what you don't know: Unanswerable questions for SQuAD},
}

@ARTICLE{srivastava2022beyond,
  AUTHOR = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adrià and others},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2206.04615},
  TITLE = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
}

@ARTICLE{bowman2021will,
  AUTHOR = {Bowman, Samuel R and Dahl, George E},
  DATE = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2104.02145},
  TITLE = {What Will it Take to Fix Benchmarking in Natural Language Understanding?},
}

@ARTICLE{goodfellow2014explaining,
  AUTHOR = {Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  DATE = {2014},
  JOURNALTITLE = {arXiv preprint arXiv:1412.6572},
  TITLE = {Explaining and harnessing adversarial examples},
}

@INPROCEEDINGS{recht2019imagenet,
  AUTHOR = {Recht, Benjamin and Roelofs, Rebecca and Schmidt, Ludwig and Shankar, Vaishaal},
  ORGANIZATION = {PMLR},
  BOOKTITLE = {International Conference on Machine Learning},
  DATE = {2019},
  PAGES = {5389--5400},
  TITLE = {Do imagenet classifiers generalize to imagenet?},
}

@ARTICLE{beyer2020we,
  AUTHOR = {Beyer, Lucas and Hénaff, Olivier J and Kolesnikov, Alexander and Zhai, Xiaohua and Oord, Aäron van den},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2006.07159},
  TITLE = {Are we done with imagenet?},
}

@ARTICLE{li2022mask,
  AUTHOR = {Li, Feng and Zhang, Hao and Liu, Shilong and Zhang, Lei and Ni, Lionel M and Shum, Heung-Yeung and others},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2206.02777},
  TITLE = {Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation},
}

@INPROCEEDINGS{koehn2005europarl,
  AUTHOR = {Koehn, Philipp},
  BOOKTITLE = {Proceedings of machine translation summit x: papers},
  DATE = {2005},
  PAGES = {79--86},
  TITLE = {Europarl: A parallel corpus for statistical machine translation},
}

@MISC{Gokaslan2019OpenWeb,
  AUTHOR = {Gokaslan, Aaron and Cohen, Vanya},
  DATE = {2019},
  TITLE = {OpenWebText Corpus},
}

@ARTICLE{xue2020mt5,
  AUTHOR = {Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2010.11934},
  TITLE = {mT5: A massively multilingual pre-trained text-to-text transformer},
}

@ARTICLE{wenzek2019ccnet,
  AUTHOR = {Wenzek, Guillaume and Lachaux, Marie-Anne and Conneau, Alexis and Chaudhary, Vishrav and Guzmán, Francisco and Joulin, Armand and Grave, Edouard},
  DATE = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1911.00359},
  TITLE = {Ccnet: Extracting high quality monolingual datasets from web crawl data},
}

@ARTICLE{bandy2021addressing,
  AUTHOR = {Bandy, Jack and Vincent, Nicholas},
  DATE = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2105.05241},
  TITLE = {Addressing" documentation debt" in machine learning research: A retrospective datasheet for bookcorpus},
}

@ARTICLE{gao2017knowledge,
  AUTHOR = {Gao, Jiyang and Li, Zhen and Nevatia, Ram and others},
  DATE = {2017},
  JOURNALTITLE = {arXiv preprint arXiv:1711.07607},
  TITLE = {Knowledge concentration: Learning 100k object classifiers in a single CNN},
}

@INPROCEEDINGS{shao2019objects365,
  AUTHOR = {Shao, Shuai and Li, Zeming and Zhang, Tianyuan and Peng, Chao and Yu, Gang and Zhang, Xiangyu and Li, Jing and Sun, Jian},
  BOOKTITLE = {Proceedings of the IEEE/CVF international conference on computer vision},
  DATE = {2019},
  PAGES = {8430--8439},
  TITLE = {Objects365: A large-scale, high-quality dataset for object detection},
}

@ARTICLE{yuan2022wudaomm,
  AUTHOR = {Yuan, Sha and Shuai, Zhao and Jiahong, Leng and Zhao, Xue and Hanyu, Zhao and Jie, Tang},
  DATE = {2022},
  JOURNALTITLE = {arXiv preprint arXiv:2203.11480},
  TITLE = {WuDaoMM: A large-scale Multi-Modal Dataset for Pre-training models},
}

@INPROCEEDINGS{srinivasan2021wit,
  AUTHOR = {Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc},
  BOOKTITLE = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  DATE = {2021},
  PAGES = {2443--2449},
  TITLE = {Wit: Wikipedia-based image text dataset for multimodal multilingual machine learning},
}

@ARTICLE{tiedemann2018emerging,
  AUTHOR = {Tiedemann, Jörg},
  DATE = {2018},
  JOURNALTITLE = {arXiv preprint arXiv:1802.00273},
  TITLE = {Emerging language spaces learned from massively multilingual corpora},
}

@ARTICLE{mayer2014creating,
  AUTHOR = {Mayer, Thomas and Cysouw, Michael},
  DATE = {2014},
  JOURNALTITLE = {Oceania},
  NUMBER = {273},
  PAGES = {40},
  TITLE = {Creating a massively parallel Bible corpus},
  VOLUME = {135},
}

@INPROCEEDINGS{zellers2019recognition,
  AUTHOR = {Zellers, Rowan and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  BOOKTITLE = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  DATE = {2019},
  PAGES = {6720--6731},
  TITLE = {From recognition to cognition: Visual commonsense reasoning},
}

@INPROCEEDINGS{antol2015vqa,
  AUTHOR = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  BOOKTITLE = {Proceedings of the IEEE international conference on computer vision},
  DATE = {2015},
  PAGES = {2425--2433},
  TITLE = {Vqa: Visual question answering},
}

@INPROCEEDINGS{zhang2016yin,
  AUTHOR = {Zhang, Peng and Goyal, Yash and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  BOOKTITLE = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  DATE = {2016},
  PAGES = {5014--5022},
  TITLE = {Yin and yang: Balancing and answering binary visual questions},
}

@INPROCEEDINGS{goyal2017making,
  AUTHOR = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  BOOKTITLE = {Proceedings of the IEEE conference on computer vision and pattern recognition},
  DATE = {2017},
  PAGES = {6904--6913},
  TITLE = {Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
}

@INPROCEEDINGS{hudson2019gqa,
  AUTHOR = {Hudson, Drew A and Manning, Christopher D},
  BOOKTITLE = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  DATE = {2019},
  PAGES = {6700--6709},
  TITLE = {Gqa: A new dataset for real-world visual reasoning and compositional question answering},
}

@ARTICLE{shekhar2017foil,
  AUTHOR = {Shekhar, Ravi and Pezzelle, Sandro and Klimovich, Yauhen and Herbelot, Aurélie and Nabi, Moin and Sangineto, Enver and Bernardi, Raffaella},
  DATE = {2017},
  JOURNALTITLE = {arXiv preprint arXiv:1705.01359},
  TITLE = {Foil it! find one mismatch between image and language caption},
}

@ARTICLE{ribeiro2020beyond,
  AUTHOR = {Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2005.04118},
  TITLE = {Beyond accuracy: Behavioral testing of NLP models with CheckList},
}

@INPROCEEDINGS{parcalabescu-etal-2022-valse,
  AUTHOR = {Parcalabescu, Letitia and Cafagna, Michele and Muradjan, Lilitta and Frank, Anette and Calixto, Iacer and Gatt, Albert},
  PUBLISHER = {Association for Computational Linguistics},
  URL = {https://aclanthology.org/2022.acl-long.567},
  BOOKTITLE = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  DATE = {2022-05},
  PAGES = {8253--8280},
  TITLE = {{VALSE}: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena},
}

@ARTICLE{sheng2019woman,
  AUTHOR = {Sheng, Emily and Chang, Kai-Wei and Natarajan, Premkumar and Peng, Nanyun},
  DATE = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1909.01326},
  TITLE = {The woman worked as a babysitter: On biases in language generation},
}

@INPROCEEDINGS{dhamala2021bold,
  AUTHOR = {Dhamala, Jwala and Sun, Tony and Kumar, Varun and Krishna, Satyapriya and Pruksachatkun, Yada and Chang, Kai-Wei and Gupta, Rahul},
  BOOKTITLE = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  DATE = {2021},
  PAGES = {862--872},
  TITLE = {Bold: Dataset and metrics for measuring biases in open-ended language generation},
}

@ARTICLE{prabhu2020large,
  AUTHOR = {Prabhu, Vinay Uday and Birhane, Abeba},
  DATE = {2020},
  JOURNALTITLE = {arXiv preprint arXiv:2006.16923},
  TITLE = {Large image datasets: A pyrrhic win for computer vision?},
}

@ARTICLE{birhane2021multimodal,
  AUTHOR = {Birhane, Abeba and Prabhu, Vinay Uday and Kahembwe, Emmanuel},
  DATE = {2021},
  JOURNALTITLE = {arXiv preprint arXiv:2110.01963},
  TITLE = {Multimodal datasets: misogyny, pornography, and malignant stereotypes},
}

@ARTICLE{strubell2019energy,
  AUTHOR = {Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  DATE = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1906.02243},
  TITLE = {Energy and policy considerations for deep learning in NLP},
}

@ARTICLE{lottick2019energy,
  AUTHOR = {Lottick, Kadan and Susai, Silvia and Friedler, Sorelle A and Wilson, Jonathan P},
  DATE = {2019},
  JOURNALTITLE = {arXiv preprint arXiv:1911.08354},
  TITLE = {Energy Usage Reports: Environmental awareness as part of algorithmic accountability},
}

@ARTICLE{henderson2020towards,
  AUTHOR = {Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle},
  DATE = {2020},
  JOURNALTITLE = {Journal of Machine Learning Research},
  NUMBER = {248},
  PAGES = {1--43},
  TITLE = {Towards the systematic reporting of the energy and carbon footprints of machine learning},
  VOLUME = {21},
}

@INPROCEEDINGS{guo2016ms,
  AUTHOR = {Guo, Yandong and Zhang, Lei and Hu, Yuxiao and He, Xiaodong and Gao, Jianfeng},
  ORGANIZATION = {Springer},
  BOOKTITLE = {European conference on computer vision},
  DATE = {2016},
  PAGES = {87--102},
  TITLE = {Ms-celeb-1m: A dataset and benchmark for large-scale face recognition},
}

